{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Memory monitor\n",
    "from my_memory_profiler import profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Calcular Extension</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_extension(data_dir, sample_rate, time_leng, overlap):\n",
    "\n",
    "    def label_generator(data_dir):\n",
    "        data_list = []\n",
    "        \n",
    "        for dirname, _, filenames in os.walk(data_dir):\n",
    "            for filename in filenames:\n",
    "                if filename.endswith('.wav'):  \n",
    "                    identifiers = filename.split('.')[0].split('_')\n",
    "                    Speaker_ID = int(identifiers[-1])\n",
    "                    Label = 1 if identifiers[0] == 'PD' else 0\n",
    "                    data_list.append({\n",
    "                        \"Speaker_ID\": Speaker_ID,\n",
    "                        \"Label\": Label,\n",
    "                        \"FileName\": filename\n",
    "                    })\n",
    "        \n",
    "        audio_labels = pd.DataFrame(data_list)\n",
    "            \n",
    "        return audio_labels\n",
    "    \n",
    "    def num_seg(data_dir, audio_labels, SAMPLE_RATE, time_leng, overloap, output_csv=None, filenames=False):\n",
    "        sample_leng=int(time_leng*SAMPLE_RATE)\n",
    "        segments_info=[]\n",
    "\n",
    "        for data_ind, audio_label in enumerate(audio_labels.values):\n",
    "            file_name=audio_label[-1]\n",
    "            data_path=os.path.join(data_dir, file_name)\n",
    "            audio, sample_rate = librosa.load(data_path, sr=SAMPLE_RATE)\n",
    "            audio_len=len(audio)\n",
    "            audio=audio/np.max(abs(audio))\n",
    "            indx=[i for i,x in enumerate(np.sqrt(abs(audio))) if x>.30]\n",
    "            segments=0\n",
    "            if (indx[0]+sample_leng)<audio_len:\n",
    "                for i in range(int((-indx[0]+indx[len(indx)-1])/(sample_leng/overloap))):\n",
    "                    ind_start = i * int(sample_leng/overloap)+indx[0]\n",
    "                    ind_end = ind_start + sample_leng\n",
    "                    if ind_end <= indx[-1]:\n",
    "                        segments+=1\n",
    "                if filenames:\n",
    "                    segments_info.append({\n",
    "                        'Filename': file_name,\n",
    "                        'Segments': segments})\n",
    "                else: \n",
    "                    segments_info.append({'Segments':segments})\n",
    "                \n",
    "                print(\" Processed {}/{} files\".format(data_ind,2902),end='\\n')\n",
    "            else:\n",
    "                print(\" Processed {}/{} files\".format(data_ind,2902),end='\\n')\n",
    "                if filenames:\n",
    "                    segments_info.append({\n",
    "                        'Filename': file_name,\n",
    "                        'Segments': segments})\n",
    "                else: \n",
    "                    segments_info.append({'Segments':segments})\n",
    "        \n",
    "        df_segments = pd.DataFrame(segments_info)\n",
    "        if(output_csv is None):\n",
    "            return df_segments\n",
    "        else:\n",
    "            df_segments.to_csv(output_csv, index=False)\n",
    "    \n",
    "    labels=label_generator(data_dir)\n",
    "    segments=num_seg(data_dir, labels, sample_rate, time_leng, overlap)\n",
    "    extension_DB=pd.concat([labels, segments], axis=1)\n",
    "    extension_DB.to_csv('extension.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Funciones de preprocesado</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_select_signals(data_path, sample_rate):\n",
    "    segment_length=0.4\n",
    "    overlap_factor=2\n",
    "    amplitude_threshold=0.30\n",
    "    audio, _ = librosa.load(data_path, sr=sample_rate)\n",
    "    audio_len = len(audio)\n",
    "    audio = audio / np.max(np.abs(audio)) \n",
    "\n",
    "    time_length = segment_length\n",
    "    sample_length = int(time_length * sample_rate)\n",
    "    overlap = overlap_factor\n",
    "\n",
    "    signals = []\n",
    "    y_label = []\n",
    "    subject_group = []\n",
    "\n",
    "    indx = [i for i, x in enumerate(np.sqrt(np.abs(audio))) if x > amplitude_threshold]\n",
    "\n",
    "    segments = 0\n",
    "    if len(indx) > 0 and (indx[0] + sample_length) < audio_len:\n",
    "        for i in range(int((-indx[0] + indx[-1]) / (sample_length / overlap))):\n",
    "            ind_start = i * int(sample_length / overlap) + indx[0]\n",
    "            ind_end = ind_start + sample_length\n",
    "            if ind_end <= indx[-1]:\n",
    "                signal = np.zeros(sample_length)\n",
    "                signal = audio[ind_start:int(ind_end)]\n",
    "                signals.append(signal)\n",
    "                y_label.append('Label') \n",
    "                subject_group.append('Speaker_ID')  \n",
    "                segments += 1\n",
    "\n",
    "    signals = np.stack(signals, axis=0) if signals else np.empty((0, sample_length))\n",
    "    y_label = np.array(y_label)\n",
    "    subject_group = np.array(subject_group)\n",
    "\n",
    "    return signals\n",
    "\n",
    "def to_spectrogram(signal, sample_rate):\n",
    "    n_fft = 2048\n",
    "    win_length = int(0.015*sample_rate) \n",
    "    hop_length = int(0.010*sample_rate)\n",
    "    n_mels = 65 \n",
    "\n",
    "    mel_spectrogram = T.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=n_fft,\n",
    "        win_length=win_length,\n",
    "        hop_length=hop_length,\n",
    "        center=True,\n",
    "        pad_mode=\"reflect\",\n",
    "        power=2.0,\n",
    "        norm=\"slaney\",\n",
    "        n_mels=n_mels,\n",
    "        mel_scale=\"htk\",\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    mel_spect = librosa.power_to_db(mel_spectrogram(torch.from_numpy(signal)))\n",
    "    mel_spect_norm=scaler.fit_transform(mel_spect)\n",
    "    \n",
    "    return mel_spect_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Definici√≥n del Dataset</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAudioDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, sample_rate, to_spectrogram=False, extension_path=None):\n",
    "        \n",
    "        if extension_path is None:\n",
    "            calculate_extension(data_dir)\n",
    "        else:\n",
    "            extension=pd.read_csv(extension_path)\n",
    "\n",
    "        self.labels=extension['Label'].values\n",
    "        self.IDs=extension['Speaker_ID'].values\n",
    "        self.filenames=extension['FileName'].values\n",
    "        self.num_segs=extension['Segments'].values\n",
    "        self.spec_id_to_file_id = np.concatenate([np.full(count, idx) for idx, count in enumerate(self.num_segs)])\n",
    "\n",
    "        # sample rate y path al directorio\n",
    "        self.sample_rate=sample_rate\n",
    "        self.data_dir=data_dir\n",
    "\n",
    "        # to_spectrogram: True or False\n",
    "        self.to_spectrogram=to_spectrogram\n",
    "\n",
    "        # signal index\n",
    "        signal_index=[]\n",
    "        for number in self.num_segs:\n",
    "            for i in range(number):\n",
    "                signal_index.append(i)\n",
    "\n",
    "        self.signal_index=signal_index\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        # numero de segmentos/espectrogramas que puede obtener getitem\n",
    "        return len(self.spec_id_to_file_id)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # mapeo de indices: file_index es el que se usa para hacer el fetch al DB. \n",
    "        file_index=self.spec_id_to_file_id[idx]\n",
    "\n",
    "        ### if(file_index in self.isincache): \n",
    "\n",
    "        # data_path = directory/path + /filename.wav\n",
    "        data_path=os.path.join(self.data_dir, self.filenames[file_index])\n",
    "\n",
    "        print(f\"fetched segment {self.signal_index[idx]} of audio {self.filenames[file_index]}\")\n",
    "\n",
    "        # audio, sample_rate = librosa.load(data_path, sr=SAMPLE_RATE)\n",
    "        label=self.labels[file_index]\n",
    "        subject_group= self.IDs[file_index]\n",
    "\n",
    "        signals=process_select_signals(data_path, self.sample_rate)\n",
    "        \n",
    "        if(self.to_spectrogram):\n",
    "            audio=to_spectrogram(signals[self.signal_index[idx]], self.sample_rate)\n",
    "            ### self.cache = [to_spectrogram(sig) for sig in signals_cache]\n",
    "        else:\n",
    "            audio=signals[idx]\n",
    "            ### self.cache=signals\n",
    "        \n",
    "        return audio, label, subject_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Pruebas inciales</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obtenci√≥n de la extensi√≥n si no se dispone de ella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_NeuroV = 'neurovoz/zenodo_upload/audios/'\n",
    "SAMPLE_RATE=44100\n",
    "calculate_extension(DATA_PATH_NeuroV, SAMPLE_RATE, time_leng=0.4, overlap=2) # genera extension.csv en el cwd\n",
    "extension_DB=pd.read_csv('extension.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Demostraci√≥n de integridad de labels y sujetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE=extension_DB['Segments'].sum()\n",
    "BATCH_SIZE=9\n",
    "\n",
    "# Dataset\n",
    "datasetAudio = CustomAudioDataset(extension_DB, DATA_PATH_NeuroV, SAMPLE_RATE, to_spectrogram=True)\n",
    "\n",
    "# DataLoader\n",
    "dataloader = DataLoader(datasetAudio, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "spectrogram_batch, label_batch, subject_batch = next(iter(dataloader))\n",
    "\n",
    "\n",
    "figure = plt.figure(figsize=(8,8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1,BATCH_SIZE+1):\n",
    "    sample_idx= i-1\n",
    "    img = spectrogram_batch[sample_idx]\n",
    "    label=label_batch[sample_idx]\n",
    "    subject=subject_batch[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    if label:\n",
    "        title='PD'\n",
    "    else:\n",
    "        title='HC'\n",
    "    plt.title('{}, ID:{}'.format(title,subject))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Ejecuci√≥n dentro de un bucle de entrenamiento</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "iters=int(DATASET_SIZE/BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "dataloader = DataLoader(datasetAudio, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "for epoch in range(200):\n",
    "\n",
    "    for i in range(iters):\n",
    "\n",
    "        spectrogram_batch, label_batch, subject_batch = next(iter(dataloader))\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
