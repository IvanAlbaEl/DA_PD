{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE=44100\n",
    "DATA_PATH_NeuroV = 'neurovoz/zenodo_upload/audios/'\n",
    "labels='labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_seg(data, SAMPLE_RATE, output_csv):\n",
    "    time_leng=0.4\n",
    "    sample_leng=int(time_leng*SAMPLE_RATE)\n",
    "    overloap=2\n",
    "    segments_info=[]\n",
    "\n",
    "\n",
    "    #Processs data to train\n",
    "    for data_ind, file_path in enumerate(data.Path):\n",
    "        audio, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "        audio_len=len(audio)\n",
    "        #print(audio_len)\n",
    "        #plt.plot(audio)\n",
    "        audio=audio/np.max(abs(audio))\n",
    "        indx=[i for i,x in enumerate(np.sqrt(abs(audio))) if x>.30]\n",
    "        segments=0\n",
    "        if (indx[0]+sample_leng)<audio_len:\n",
    "            for i in range(int((-indx[0]+indx[len(indx)-1])/(sample_leng/overloap))):\n",
    "                ind_start = i * int(sample_leng/overloap)+indx[0]\n",
    "                ind_end = ind_start + sample_leng\n",
    "                if ind_end <= indx[-1]:\n",
    "                    segments+=1\n",
    "            \n",
    "            segments_info.append({\n",
    "                'Filename': file_path,\n",
    "                'Segments': segments,\n",
    "                \n",
    "            })\n",
    "            print(\" Processed {}/{} files\".format(data_ind,len(data)-1),end='')\n",
    "        else:\n",
    "             print(\" Processed {}/{} files\".format(data_ind,len(data)-1),end='')\n",
    "             segments_info.append({\n",
    "                'Filename': file_path,\n",
    "                'Segments': 0,\n",
    "                \n",
    "            })\n",
    "    \n",
    "\n",
    "    df_segments = pd.DataFrame(segments_info)\n",
    "\n",
    "    df_segments.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAudioDataset(Dataset):\n",
    "    def __init__(self, audio_labels, data_dir, transform=None, target_transform=None):\n",
    "        self.audio_labels=pd.read_csv(audio_labels) # se obtiene de un script aparte y contiene [ID, label, filename]\n",
    "        self.data_dir=data_dir\n",
    "        self.transform=transform\n",
    "        self.target_transform=target_transform #transformacion de los labels\n",
    "    def __len__(self):\n",
    "        return len(self.audio_labels)\n",
    "    def __getitem__(self, idx):\n",
    "        data_path=os.path.join(self.data_dir, self.audio_labels[idx, -1]) #directory/path + /filename.wav\n",
    "        audio, sample_rate = librosa.load(data_path, sr=SAMPLE_RATE)\n",
    "        label=self.audio_labels[idx, 1]\n",
    "        subject_group= self.audio_labels[idx, 0]\n",
    "        if self.transform:\n",
    "            audio=self.transform(audio)\n",
    "        if self.target_transform(audio):\n",
    "            label=self.target_transform(label)\n",
    "        return audio, subject_group, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset\n",
    "datasetAudio = CustomAudioDataset(labels, DATA_PATH_NeuroV)\n",
    "\n",
    "#DataLoader\n",
    "dataloader = DataLoader(datasetAudio, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
